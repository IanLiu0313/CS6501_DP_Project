{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 344,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "dNyEd3-Kvd4n",
        "outputId": "a596580b-504f-4416-9661-ff7c6bcda9f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install torchvision == 11.7"
      ],
      "metadata": {
        "id": "xvpJJVRzK1fm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "075df0f0-ff77-4509-c56c-94dfa601d761"
      },
      "execution_count": 345,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch\n",
            "  Using cached pytorch-1.0.2.tar.gz (689 bytes)\n",
            "Building wheels for collected packages: pytorch\n",
            "  Building wheel for pytorch (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for pytorch\u001b[0m\n",
            "\u001b[?25h  Running setup.py clean for pytorch\n",
            "Failed to build pytorch\n",
            "Installing collected packages: pytorch\n",
            "    Running setup.py install for pytorch ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-ql5vy0da/pytorch_3d7f6601c3354cba8af221cb39622acb/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-ql5vy0da/pytorch_3d7f6601c3354cba8af221cb39622acb/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-7m_4pmud/install-record.txt --single-version-externally-managed --compile --install-headers /usr/local/include/python3.8/pytorch Check the logs for full command output.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Subset"
      ],
      "metadata": {
        "id": "CmfvAp2nvgQI"
      },
      "execution_count": 346,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from PIL import Image\n",
        "from sklearn.utils import shuffle\n",
        "from glob import glob\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "c27anGwcvhtQ"
      },
      "execution_count": 347,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import numpy as np\n",
        "from IPython.display import clear_output\n",
        "import itertools\n",
        "import numpy.ma as ma\n",
        "from threading import Thread\n",
        "from torch.utils.data.dataset import random_split\n"
      ],
      "metadata": {
        "id": "sll90Wq9XGCB"
      },
      "execution_count": 348,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from torchvision.io import read_image\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
        "        self.img_labels = pd.read_csv(annotations_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "        image = cv2.imread(img_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "hCDk7NGWvww4"
      },
      "execution_count": 349,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dirs\n",
        "WORKING_DIR = '/content/drive/MyDrive/CS6501_DP/Project/'\n",
        "INPUT_DIR = '/content/drive/MyDrive/CS6501_DP/Project/input/'\n",
        "# WORKING_DIR = '/content/drive/MyDrive/Third Year/Data Privacy/Project'\n",
        "# INPUT_DIR = '/content/drive/MyDrive/Third Year/Data Privacy/Project/input'\n",
        "\n",
        "# classes\n",
        "imgClasses = ['Cardiomegaly', 'Emphysema', 'Effusion', \n",
        "              'Hernia', 'Infiltration', 'Mass', 'Nodule', \n",
        "              'Atelectasis','Pneumothorax','Pleural_Thickening', \n",
        "              'Pneumonia', 'Fibrosis', 'Edema', 'Consolidation',\n",
        "              'No Finding']"
      ],
      "metadata": {
        "id": "CpKjXhxnwydg"
      },
      "execution_count": 350,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import data\n",
        "os.chdir(INPUT_DIR)\n",
        "all_xray_df = pd.read_csv('sample_labels.csv')\n",
        "\n",
        "# obtain path to each image and add to dataframe\n",
        "# use glob module to intelligently parse all files\n",
        "# add to dictionary with key as filename\n",
        "all_image_paths = {os.path.basename(x): x for x in \n",
        "                   glob(os.path.join('data', 'images', '*.png'))}\n",
        "\n",
        "print('Scans found:', len(all_image_paths), ', Total Rows', all_xray_df.shape[0])\n",
        "\n",
        "all_xray_df['path'] = all_xray_df['Image Index'].map(all_image_paths.get)\n",
        "\n",
        "\n",
        "\n",
        "# this is multi-task, multi-class classification\n",
        "# rename null finding\n",
        "# split the string description \n",
        "all_xray_df['Finding Labels']  = all_xray_df['Finding Labels'].replace('No Finding', '')\n",
        "#all_labels = np.unique(list(chain(*all_xray_df['Finding Labels'].map(lambda x: x.split('|')).tolist())))\n",
        "all_labels = list({x for l in all_xray_df['Finding Labels'].str.split('|') for x in l})\n",
        "\n",
        "# obtain list of unique diseases\n",
        "all_labels = [x for x in all_labels if len(x) > 0]\n",
        "print('All Labels ({}): {}'.format(len(all_labels), all_labels))\n",
        "\n",
        "#perform one-hot encoding based on diseases extracted\n",
        "for c_label in all_labels:\n",
        "    if len(c_label)> 1: # leave out empty labels\n",
        "        all_xray_df[c_label] = all_xray_df['Finding Labels'].map(lambda finding: 1.0 if c_label in finding else 0)\n",
        "\n",
        "# drop unused columns\n",
        "all_xray_df = all_xray_df.drop(['OriginalImagePixelSpacing_x', 'OriginalImagePixelSpacing_y',\n",
        "                               'Finding Labels',\n",
        "                               'Follow-up #',\n",
        "                               'OriginalImageWidth','OriginalImageHeight'\n",
        "                               ], axis=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "GcDgc2ZDzmIy",
        "outputId": "8219e183-4f6c-4974-80ad-7c9638f54ab2"
      },
      "execution_count": 351,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scans found: 5606 , Total Rows 5606\n",
            "All Labels (14): ['Fibrosis', 'Pneumothorax', 'Edema', 'Pneumonia', 'Hernia', 'Mass', 'Atelectasis', 'Nodule', 'Pleural_Thickening', 'Cardiomegaly', 'Effusion', 'Emphysema', 'Consolidation', 'Infiltration']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_xray_df_sel = all_xray_df[['Image Index', 'Fibrosis', 'Pneumothorax', 'Atelectasis',\n",
        "       'Infiltration', 'Nodule', 'Pneumonia', 'Consolidation', 'Hernia',\n",
        "       'Emphysema', 'Pleural_Thickening', 'Effusion', 'Edema', 'Cardiomegaly',\n",
        "       'Mass']]"
      ],
      "metadata": {
        "id": "8aUQJ1441ShC"
      },
      "execution_count": 352,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "lJ-dWLholmJE"
      },
      "execution_count": 353,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls_codes = list()\n",
        "ls_save = list()\n",
        "for i in range(len(all_xray_df_sel)):\n",
        "  for disease_name in [ 'Fibrosis', 'Pneumothorax', 'Atelectasis', 'Infiltration', 'Nodule', 'Pneumonia', 'Consolidation', 'Hernia', 'Emphysema', 'Pleural_Thickening', 'Effusion', 'Edema', 'Cardiomegaly', 'Mass']:\n",
        "    code_per = all_xray_df_sel.loc[i, disease_name]\n",
        "    if code_per == 1:\n",
        "      ls_save.append([all_xray_df_sel.loc[i, 'Image Index'], disease_name])\n",
        "      # code_image = code_image + str(int(code_per))\n",
        "  \n",
        "#   ls_codes.append(code_image)\n",
        "# all_xray_df_sel['Code'] = ls_codes\n",
        "# all_xray_df_save = all_xray_df_sel[['Image Index', 'Code']]\n",
        "all_xray_df_save = pd.DataFrame(ls_save, columns=['Image Index', 'Code'])\n",
        "label_encode = LabelEncoder()\n",
        "all_xray_df_save['Code'] = label_encode.fit_transform(all_xray_df_save['Code'])"
      ],
      "metadata": {
        "id": "HYewT3ki1T6x"
      },
      "execution_count": 354,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(INPUT_DIR)\n",
        "all_xray_df_save.to_csv('sample_labels_reformat.csv', index=False)"
      ],
      "metadata": {
        "id": "Wr-mLPO55a2a"
      },
      "execution_count": 355,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(all_xray_df_save, test_size=0.2)\n",
        "train.to_csv('sample_labels_train.csv', index=False)\n",
        "test.to_csv('sample_labels_test.csv', index=False)"
      ],
      "metadata": {
        "id": "EPNiriCO6suy"
      },
      "execution_count": 356,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "jwhuc6Zxw9Rv",
        "outputId": "1e73095a-5909-462f-b10b-796f242d8ac0"
      },
      "execution_count": 357,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Image Index  Code\n",
              "1502  00011925_010.png     8\n",
              "2099  00015818_001.png     8\n",
              "479   00004156_002.png     4\n",
              "575   00004893_036.png     0\n",
              "2065  00015606_006.png     3\n",
              "...                ...   ...\n",
              "3775  00029174_003.png     8\n",
              "988   00008303_000.png    10\n",
              "1460  00011731_006.png     8\n",
              "377   00003186_005.png     8\n",
              "2615  00019271_058.png     0\n",
              "\n",
              "[3147 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-be6e9441-4b4a-467b-b1ca-033f50e9d393\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image Index</th>\n",
              "      <th>Code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1502</th>\n",
              "      <td>00011925_010.png</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2099</th>\n",
              "      <td>00015818_001.png</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>479</th>\n",
              "      <td>00004156_002.png</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>575</th>\n",
              "      <td>00004893_036.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2065</th>\n",
              "      <td>00015606_006.png</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3775</th>\n",
              "      <td>00029174_003.png</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>988</th>\n",
              "      <td>00008303_000.png</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1460</th>\n",
              "      <td>00011731_006.png</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>377</th>\n",
              "      <td>00003186_005.png</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2615</th>\n",
              "      <td>00019271_058.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3147 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-be6e9441-4b4a-467b-b1ca-033f50e9d393')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-be6e9441-4b4a-467b-b1ca-033f50e9d393 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-be6e9441-4b4a-467b-b1ca-033f50e9d393');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 357
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# transformations\n",
        "transformations = transforms.Compose([transforms.ToPILImage(), \n",
        "                                      transforms.Resize((32,32)), \n",
        "                                      transforms.ToTensor(),\n",
        "                                     transforms.Normalize([0.5], [0.5])])\n",
        "\n",
        "os.chdir(INPUT_DIR)\n",
        "image_dir = INPUT_DIR +'/data/images'\n",
        "train_data = CustomImageDataset(annotations_file='sample_labels_train.csv', img_dir=image_dir, transform=transformations)\n",
        "test_data = CustomImageDataset(annotations_file='sample_labels_test.csv', img_dir=image_dir, transform=transformations)"
      ],
      "metadata": {
        "id": "iRfXP6Ip7HuK"
      },
      "execution_count": 358,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('The shape of tensor for 50th image in train dataset: ',train_data[49][0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "uykUIlOIDl8c",
        "outputId": "a27cdb07-4782-45c1-8258-d3f1d93686cb"
      },
      "execution_count": 359,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of tensor for 50th image in train dataset:  torch.Size([3, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# training and test data info\n",
        "print('num training data: {0}'.format(len(train_data)))\n",
        "print('num test data: {0}'.format(len(test_data)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "9l89l7dFWZ3V",
        "outputId": "4698a66e-603f-4322-95e1-3c951e4e943d"
      },
      "execution_count": 360,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num training data: 3147\n",
            "num test data: 787\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=50, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=50, shuffle=True)\n"
      ],
      "metadata": {
        "id": "xzuFmd93bVvg"
      },
      "execution_count": 361,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Subset\n",
        "num_teachers = 100\n",
        "\n",
        "teacher_loaders = []  #list of dataloaders\n",
        "\n",
        "# data_size = 35 # mnist_trainset/num_teachers\n",
        "data_size = 30 # mnist_trainset/num_teachers\n",
        "\n",
        "for i in range(num_teachers):\n",
        "    \n",
        "    indices = list(range(i*data_size, (i+1) *data_size)) #creating subsets of 600 data_size\n",
        "    subset_data = Subset(train_data, indices)\n",
        "    \n",
        "    loader = torch.utils.data.DataLoader(subset_data, batch_size=50, num_workers=2)\n",
        "    teacher_loaders.append(loader)"
      ],
      "metadata": {
        "id": "lTxWcmhnbVzu"
      },
      "execution_count": 362,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Active device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "UDuwP9FNbV2O",
        "outputId": "c7991c92-e9d5-429e-9ae0-9e1ca245ff2a"
      },
      "execution_count": 363,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Active device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "    \n",
        "# obtain one batch of training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "images = images.numpy()"
      ],
      "metadata": {
        "id": "mV97K4-qbV4h"
      },
      "execution_count": 364,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# # plot the images in the batch, along with the corresponding labels\n",
        "# fig = plt.figure(figsize=(32, 4))\n",
        "# for idx in np.arange(20):\n",
        "#     ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
        "#     ax.imshow(np.squeeze(images[idx]), cmap='gray')\n",
        "#     # print out the correct label for each image.item() gets the value contained in a Tensor\n",
        "#     ax.set_title(str(labels[idx].item()))"
      ],
      "metadata": {
        "id": "fpt73A6jjvDf"
      },
      "execution_count": 365,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn, optim\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "90xxnYj-bV6y"
      },
      "execution_count": 366,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Classifier(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "    \n",
        "        self.conv1 = nn.Conv2d(3, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(5*10*10, 50)\n",
        "        self.fc2 = nn.Linear(50, 14)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        x = x.view(x.size(0), 5*10*10)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x)"
      ],
      "metadata": {
        "id": "zGyl3UsphaHO"
      },
      "execution_count": 367,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "models = []\n",
        "for i in range(num_teachers):\n",
        "    model = Classifier()\n",
        "    model.to(device)\n",
        "    criterion = nn.NLLLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "    running_loss = 0\n",
        "    teacher_loss = []\n",
        "    for e in range(epochs):\n",
        "        running_loss = 0\n",
        "        for images, labels in teacher_loaders[i]:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            log_ps = model(images)\n",
        "            loss = criterion(log_ps, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "    teacher_loss.append(running_loss)\n",
        "    \n",
        "    print(\"Training teacher: {}/{}.. \".format(i+1, num_teachers), \"Training Loss: {:.3f}.. \".format(running_loss))\n",
        "    models.append(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "K0BTgZnVhaJ1",
        "outputId": "e5baf0c8-f4a3-49ca-b8c3-1e02507acb73"
      },
      "execution_count": 368,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-367-1095ff33de73>:19: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training teacher: 1/100..  Training Loss: 2.627.. \n",
            "Training teacher: 2/100..  Training Loss: 2.629.. \n",
            "Training teacher: 3/100..  Training Loss: 2.614.. \n",
            "Training teacher: 4/100..  Training Loss: 2.645.. \n",
            "Training teacher: 5/100..  Training Loss: 2.628.. \n",
            "Training teacher: 6/100..  Training Loss: 2.606.. \n",
            "Training teacher: 7/100..  Training Loss: 2.670.. \n",
            "Training teacher: 8/100..  Training Loss: 2.612.. \n",
            "Training teacher: 9/100..  Training Loss: 2.644.. \n",
            "Training teacher: 10/100..  Training Loss: 2.659.. \n",
            "Training teacher: 11/100..  Training Loss: 2.650.. \n",
            "Training teacher: 12/100..  Training Loss: 2.648.. \n",
            "Training teacher: 13/100..  Training Loss: 2.618.. \n",
            "Training teacher: 14/100..  Training Loss: 2.621.. \n",
            "Training teacher: 15/100..  Training Loss: 2.635.. \n",
            "Training teacher: 16/100..  Training Loss: 2.635.. \n",
            "Training teacher: 17/100..  Training Loss: 2.634.. \n",
            "Training teacher: 18/100..  Training Loss: 2.636.. \n",
            "Training teacher: 19/100..  Training Loss: 2.643.. \n",
            "Training teacher: 20/100..  Training Loss: 2.643.. \n",
            "Training teacher: 21/100..  Training Loss: 2.665.. \n",
            "Training teacher: 22/100..  Training Loss: 2.648.. \n",
            "Training teacher: 23/100..  Training Loss: 2.689.. \n",
            "Training teacher: 24/100..  Training Loss: 2.620.. \n",
            "Training teacher: 25/100..  Training Loss: 2.625.. \n",
            "Training teacher: 26/100..  Training Loss: 2.613.. \n",
            "Training teacher: 27/100..  Training Loss: 2.620.. \n",
            "Training teacher: 28/100..  Training Loss: 2.570.. \n",
            "Training teacher: 29/100..  Training Loss: 2.633.. \n",
            "Training teacher: 30/100..  Training Loss: 2.591.. \n",
            "Training teacher: 31/100..  Training Loss: 2.624.. \n",
            "Training teacher: 32/100..  Training Loss: 2.661.. \n",
            "Training teacher: 33/100..  Training Loss: 2.604.. \n",
            "Training teacher: 34/100..  Training Loss: 2.619.. \n",
            "Training teacher: 35/100..  Training Loss: 2.630.. \n",
            "Training teacher: 36/100..  Training Loss: 2.670.. \n",
            "Training teacher: 37/100..  Training Loss: 2.591.. \n",
            "Training teacher: 38/100..  Training Loss: 2.593.. \n",
            "Training teacher: 39/100..  Training Loss: 2.631.. \n",
            "Training teacher: 40/100..  Training Loss: 2.640.. \n",
            "Training teacher: 41/100..  Training Loss: 2.630.. \n",
            "Training teacher: 42/100..  Training Loss: 2.592.. \n",
            "Training teacher: 43/100..  Training Loss: 2.603.. \n",
            "Training teacher: 44/100..  Training Loss: 2.643.. \n",
            "Training teacher: 45/100..  Training Loss: 2.596.. \n",
            "Training teacher: 46/100..  Training Loss: 2.622.. \n",
            "Training teacher: 47/100..  Training Loss: 2.594.. \n",
            "Training teacher: 48/100..  Training Loss: 2.628.. \n",
            "Training teacher: 49/100..  Training Loss: 2.596.. \n",
            "Training teacher: 50/100..  Training Loss: 2.547.. \n",
            "Training teacher: 51/100..  Training Loss: 2.610.. \n",
            "Training teacher: 52/100..  Training Loss: 2.667.. \n",
            "Training teacher: 53/100..  Training Loss: 2.573.. \n",
            "Training teacher: 54/100..  Training Loss: 2.648.. \n",
            "Training teacher: 55/100..  Training Loss: 2.667.. \n",
            "Training teacher: 56/100..  Training Loss: 2.626.. \n",
            "Training teacher: 57/100..  Training Loss: 2.630.. \n",
            "Training teacher: 58/100..  Training Loss: 2.640.. \n",
            "Training teacher: 59/100..  Training Loss: 2.624.. \n",
            "Training teacher: 60/100..  Training Loss: 2.628.. \n",
            "Training teacher: 61/100..  Training Loss: 2.633.. \n",
            "Training teacher: 62/100..  Training Loss: 2.638.. \n",
            "Training teacher: 63/100..  Training Loss: 2.649.. \n",
            "Training teacher: 64/100..  Training Loss: 2.639.. \n",
            "Training teacher: 65/100..  Training Loss: 2.595.. \n",
            "Training teacher: 66/100..  Training Loss: 2.655.. \n",
            "Training teacher: 67/100..  Training Loss: 2.605.. \n",
            "Training teacher: 68/100..  Training Loss: 2.605.. \n",
            "Training teacher: 69/100..  Training Loss: 2.636.. \n",
            "Training teacher: 70/100..  Training Loss: 2.637.. \n",
            "Training teacher: 71/100..  Training Loss: 2.650.. \n",
            "Training teacher: 72/100..  Training Loss: 2.564.. \n",
            "Training teacher: 73/100..  Training Loss: 2.695.. \n",
            "Training teacher: 74/100..  Training Loss: 2.577.. \n",
            "Training teacher: 75/100..  Training Loss: 2.595.. \n",
            "Training teacher: 76/100..  Training Loss: 2.631.. \n",
            "Training teacher: 77/100..  Training Loss: 2.608.. \n",
            "Training teacher: 78/100..  Training Loss: 2.592.. \n",
            "Training teacher: 79/100..  Training Loss: 2.607.. \n",
            "Training teacher: 80/100..  Training Loss: 2.587.. \n",
            "Training teacher: 81/100..  Training Loss: 2.577.. \n",
            "Training teacher: 82/100..  Training Loss: 2.617.. \n",
            "Training teacher: 83/100..  Training Loss: 2.648.. \n",
            "Training teacher: 84/100..  Training Loss: 2.628.. \n",
            "Training teacher: 85/100..  Training Loss: 2.602.. \n",
            "Training teacher: 86/100..  Training Loss: 2.637.. \n",
            "Training teacher: 87/100..  Training Loss: 2.658.. \n",
            "Training teacher: 88/100..  Training Loss: 2.628.. \n",
            "Training teacher: 89/100..  Training Loss: 2.623.. \n",
            "Training teacher: 90/100..  Training Loss: 2.640.. \n",
            "Training teacher: 91/100..  Training Loss: 2.640.. \n",
            "Training teacher: 92/100..  Training Loss: 2.664.. \n",
            "Training teacher: 93/100..  Training Loss: 2.645.. \n",
            "Training teacher: 94/100..  Training Loss: 2.585.. \n",
            "Training teacher: 95/100..  Training Loss: 2.631.. \n",
            "Training teacher: 96/100..  Training Loss: 2.635.. \n",
            "Training teacher: 97/100..  Training Loss: 2.609.. \n",
            "Training teacher: 98/100..  Training Loss: 2.678.. \n",
            "Training teacher: 99/100..  Training Loss: 2.608.. \n",
            "Training teacher: 100/100..  Training Loss: 2.637.. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating the public dataset\n",
        "student_traindata = Subset(test_data, list(range(600))) #90% of Test dat as train data\n",
        "student_testdata = Subset(test_data, list(range(600, 787))) #10% of Test data as test data"
      ],
      "metadata": {
        "id": "kq0rPr02haMP"
      },
      "execution_count": 369,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating student_loaders\n",
        "student_trainloader = torch.utils.data.DataLoader(student_traindata, batch_size=50, shuffle=True)\n",
        "student_testloader = torch.utils.data.DataLoader(student_testdata, batch_size=50, shuffle=True)"
      ],
      "metadata": {
        "id": "tQbe5f0WhaOL"
      },
      "execution_count": 370,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perdict(model, dataloader):\n",
        "    \"\"\"\n",
        "    Perdicts labels for a dataset\n",
        "    Input: model and dataloader\n",
        "    \"\"\"\n",
        "    outputs = torch.zeros(0, dtype=torch.long).to(device)\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    for image, labels in dataloader:\n",
        "        image, labels = image.to(device), labels.to(device)  \n",
        "        output = model(image)\n",
        "        ps = torch.argmax(torch.exp(output), dim=1)\n",
        "        outputs = torch.cat((outputs, ps))\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "tLbU0JnmhaQa"
      },
      "execution_count": 372,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the Aggregated Teacher and Student labels by combining the predictions of Teacher models\n",
        "epsilon = 0.25\n",
        "preds = torch.zeros((len(models),600), dtype=torch.long)\n",
        "for i, model in enumerate(models):\n",
        "    results = perdict(model, student_trainloader)\n",
        "    preds[i] = results\n",
        "labels = np.array([]).astype(int)\n",
        "for image_preds in np.transpose(preds):  \n",
        "    label_counts = np.bincount(image_preds, minlength = 10)\n",
        "    beta = 1/ epsilon\n",
        "    for i in range(len(label_counts)):\n",
        "        label_counts[i] += np.random.laplace(0, beta, 1)\n",
        "    new_label = np.argmax(label_counts)\n",
        "    labels = np.append(labels, new_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "tyLHD4AQhaS0",
        "outputId": "138c43a9-60c2-4b1b-f0ac-215d7319a7a9"
      },
      "execution_count": 374,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-367-1095ff33de73>:19: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "student_labels = np.array(labels)\n",
        "preds = preds.numpy()"
      ],
      "metadata": {
        "id": "F-sVubDzhaU6"
      },
      "execution_count": 375,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "train_losses, test_losses = [], []\n",
        "model = Classifier()\n",
        "model.to(device)\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "running_loss = 0\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in student_trainloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        log_ps = model(images)\n",
        "        loss = criterion(log_ps, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        test_loss = 0\n",
        "        accuracy = 0\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            for images, labels in student_testloader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                log_ps = model(images)\n",
        "                test_loss += criterion(log_ps, labels)\n",
        "                \n",
        "                ps = torch.exp(log_ps)\n",
        "                top_p, top_class = ps.topk(1, dim=1)\n",
        "                equals = top_class == labels.view(*top_class.shape)\n",
        "                accuracy += torch.mean(equals.type(torch.FloatTensor))        \n",
        "        train_losses.append(running_loss/len(student_trainloader))\n",
        "        test_losses.append(test_loss/len(student_testloader))\n",
        "\n",
        "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
        "              \"Training Loss: {:.3f}.. \".format(running_loss/len(student_trainloader)),\n",
        "              \"Test Loss: {:.3f}.. \".format(test_loss/len(student_testloader)),\n",
        "              \"Test Accuracy: {:.3f}\".format(accuracy/len(student_testloader)))\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "9wYOIjWghaXP",
        "outputId": "7e00e457-0984-475d-a7b4-18133c96f863"
      },
      "execution_count": 376,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-367-1095ff33de73>:19: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/50..  Training Loss: 2.647..  Test Loss: 2.638..  Test Accuracy: 0.050\n",
            "Epoch: 2/50..  Training Loss: 2.637..  Test Loss: 2.629..  Test Accuracy: 0.047\n",
            "Epoch: 3/50..  Training Loss: 2.625..  Test Loss: 2.609..  Test Accuracy: 0.122\n",
            "Epoch: 4/50..  Training Loss: 2.608..  Test Loss: 2.592..  Test Accuracy: 0.197\n",
            "Epoch: 5/50..  Training Loss: 2.582..  Test Loss: 2.550..  Test Accuracy: 0.227\n",
            "Epoch: 6/50..  Training Loss: 2.546..  Test Loss: 2.522..  Test Accuracy: 0.236\n",
            "Epoch: 7/50..  Training Loss: 2.511..  Test Loss: 2.478..  Test Accuracy: 0.223\n",
            "Epoch: 8/50..  Training Loss: 2.485..  Test Loss: 2.458..  Test Accuracy: 0.234\n",
            "Epoch: 9/50..  Training Loss: 2.451..  Test Loss: 2.416..  Test Accuracy: 0.258\n",
            "Epoch: 10/50..  Training Loss: 2.451..  Test Loss: 2.417..  Test Accuracy: 0.268\n",
            "Epoch: 11/50..  Training Loss: 2.463..  Test Loss: 2.380..  Test Accuracy: 0.238\n",
            "Epoch: 12/50..  Training Loss: 2.423..  Test Loss: 2.399..  Test Accuracy: 0.226\n",
            "Epoch: 13/50..  Training Loss: 2.421..  Test Loss: 2.417..  Test Accuracy: 0.246\n",
            "Epoch: 14/50..  Training Loss: 2.434..  Test Loss: 2.373..  Test Accuracy: 0.221\n",
            "Epoch: 15/50..  Training Loss: 2.426..  Test Loss: 2.403..  Test Accuracy: 0.206\n",
            "Epoch: 16/50..  Training Loss: 2.427..  Test Loss: 2.407..  Test Accuracy: 0.239\n",
            "Epoch: 17/50..  Training Loss: 2.411..  Test Loss: 2.428..  Test Accuracy: 0.229\n",
            "Epoch: 18/50..  Training Loss: 2.415..  Test Loss: 2.390..  Test Accuracy: 0.253\n",
            "Epoch: 19/50..  Training Loss: 2.398..  Test Loss: 2.374..  Test Accuracy: 0.237\n",
            "Epoch: 20/50..  Training Loss: 2.421..  Test Loss: 2.419..  Test Accuracy: 0.236\n",
            "Epoch: 21/50..  Training Loss: 2.408..  Test Loss: 2.436..  Test Accuracy: 0.182\n",
            "Epoch: 22/50..  Training Loss: 2.431..  Test Loss: 2.404..  Test Accuracy: 0.234\n",
            "Epoch: 23/50..  Training Loss: 2.400..  Test Loss: 2.415..  Test Accuracy: 0.209\n",
            "Epoch: 24/50..  Training Loss: 2.415..  Test Loss: 2.454..  Test Accuracy: 0.224\n",
            "Epoch: 25/50..  Training Loss: 2.409..  Test Loss: 2.405..  Test Accuracy: 0.209\n",
            "Epoch: 26/50..  Training Loss: 2.396..  Test Loss: 2.430..  Test Accuracy: 0.181\n",
            "Epoch: 27/50..  Training Loss: 2.379..  Test Loss: 2.372..  Test Accuracy: 0.259\n",
            "Epoch: 28/50..  Training Loss: 2.377..  Test Loss: 2.351..  Test Accuracy: 0.258\n",
            "Epoch: 29/50..  Training Loss: 2.371..  Test Loss: 2.409..  Test Accuracy: 0.241\n",
            "Epoch: 30/50..  Training Loss: 2.388..  Test Loss: 2.400..  Test Accuracy: 0.209\n",
            "Epoch: 31/50..  Training Loss: 2.405..  Test Loss: 2.368..  Test Accuracy: 0.241\n",
            "Epoch: 32/50..  Training Loss: 2.345..  Test Loss: 2.417..  Test Accuracy: 0.214\n",
            "Epoch: 33/50..  Training Loss: 2.393..  Test Loss: 2.381..  Test Accuracy: 0.239\n",
            "Epoch: 34/50..  Training Loss: 2.369..  Test Loss: 2.412..  Test Accuracy: 0.221\n",
            "Epoch: 35/50..  Training Loss: 2.380..  Test Loss: 2.388..  Test Accuracy: 0.249\n",
            "Epoch: 36/50..  Training Loss: 2.419..  Test Loss: 2.364..  Test Accuracy: 0.233\n",
            "Epoch: 37/50..  Training Loss: 2.383..  Test Loss: 2.408..  Test Accuracy: 0.227\n",
            "Epoch: 38/50..  Training Loss: 2.391..  Test Loss: 2.429..  Test Accuracy: 0.207\n",
            "Epoch: 39/50..  Training Loss: 2.382..  Test Loss: 2.402..  Test Accuracy: 0.218\n",
            "Epoch: 40/50..  Training Loss: 2.383..  Test Loss: 2.383..  Test Accuracy: 0.246\n",
            "Epoch: 41/50..  Training Loss: 2.378..  Test Loss: 2.394..  Test Accuracy: 0.273\n",
            "Epoch: 42/50..  Training Loss: 2.378..  Test Loss: 2.392..  Test Accuracy: 0.251\n",
            "Epoch: 43/50..  Training Loss: 2.371..  Test Loss: 2.396..  Test Accuracy: 0.236\n",
            "Epoch: 44/50..  Training Loss: 2.387..  Test Loss: 2.366..  Test Accuracy: 0.231\n",
            "Epoch: 45/50..  Training Loss: 2.372..  Test Loss: 2.427..  Test Accuracy: 0.221\n",
            "Epoch: 46/50..  Training Loss: 2.383..  Test Loss: 2.371..  Test Accuracy: 0.237\n",
            "Epoch: 47/50..  Training Loss: 2.366..  Test Loss: 2.383..  Test Accuracy: 0.253\n",
            "Epoch: 48/50..  Training Loss: 2.378..  Test Loss: 2.413..  Test Accuracy: 0.238\n",
            "Epoch: 49/50..  Training Loss: 2.366..  Test Loss: 2.417..  Test Accuracy: 0.239\n",
            "Epoch: 50/50..  Training Loss: 2.370..  Test Loss: 2.414..  Test Accuracy: 0.232\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_losses, label='Training loss')\n",
        "#plt.plot(test_losses, label='Validation loss')\n",
        "plt.legend(frameon=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "QKYRLQ93haZH",
        "outputId": "558cfc30-33ab-439b-e6ce-7f8df667bd06"
      },
      "execution_count": 378,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f41ba2a2670>"
            ]
          },
          "metadata": {},
          "execution_count": 378
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 378,
              "height": 248
            },
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#plt.plot(test_losses, label='Validation loss')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "C_3rdhcH4qVQ",
        "outputId": "1ba22cf4-8e62-4c5a-dfab-05b4f80a5a11"
      },
      "execution_count": 398,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "()"
            ]
          },
          "metadata": {},
          "execution_count": 398
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_losses_1 = test_losses.copy()\n",
        "test_losses_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "BYiz1ijy19qW",
        "outputId": "6a516569-58c6-415c-93fb-7b4e5eb7ea6d"
      },
      "execution_count": 389,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor(2.6381, device='cuda:0'),\n",
              " tensor(2.6290, device='cuda:0'),\n",
              " tensor(2.6085, device='cuda:0'),\n",
              " tensor(2.5917, device='cuda:0'),\n",
              " tensor(2.5501, device='cuda:0'),\n",
              " tensor(2.5220, device='cuda:0'),\n",
              " tensor(2.4781, device='cuda:0'),\n",
              " tensor(2.4578, device='cuda:0'),\n",
              " tensor(2.4163, device='cuda:0'),\n",
              " tensor(2.4167, device='cuda:0'),\n",
              " tensor(2.3801, device='cuda:0'),\n",
              " tensor(2.3991, device='cuda:0'),\n",
              " tensor(2.4171, device='cuda:0'),\n",
              " tensor(2.3728, device='cuda:0'),\n",
              " tensor(2.4030, device='cuda:0'),\n",
              " tensor(2.4071, device='cuda:0'),\n",
              " tensor(2.4277, device='cuda:0'),\n",
              " tensor(2.3900, device='cuda:0'),\n",
              " tensor(2.3737, device='cuda:0'),\n",
              " tensor(2.4185, device='cuda:0'),\n",
              " tensor(2.4361, device='cuda:0'),\n",
              " tensor(2.4042, device='cuda:0'),\n",
              " tensor(2.4148, device='cuda:0'),\n",
              " tensor(2.4536, device='cuda:0'),\n",
              " tensor(2.4050, device='cuda:0'),\n",
              " tensor(2.4301, device='cuda:0'),\n",
              " tensor(2.3723, device='cuda:0'),\n",
              " tensor(2.3510, device='cuda:0'),\n",
              " tensor(2.4092, device='cuda:0'),\n",
              " tensor(2.3997, device='cuda:0'),\n",
              " tensor(2.3684, device='cuda:0'),\n",
              " tensor(2.4166, device='cuda:0'),\n",
              " tensor(2.3813, device='cuda:0'),\n",
              " tensor(2.4120, device='cuda:0'),\n",
              " tensor(2.3884, device='cuda:0'),\n",
              " tensor(2.3644, device='cuda:0'),\n",
              " tensor(2.4080, device='cuda:0'),\n",
              " tensor(2.4286, device='cuda:0'),\n",
              " tensor(2.4020, device='cuda:0'),\n",
              " tensor(2.3826, device='cuda:0'),\n",
              " tensor(2.3939, device='cuda:0'),\n",
              " tensor(2.3923, device='cuda:0'),\n",
              " tensor(2.3961, device='cuda:0'),\n",
              " tensor(2.3655, device='cuda:0'),\n",
              " tensor(2.4266, device='cuda:0'),\n",
              " tensor(2.3706, device='cuda:0'),\n",
              " tensor(2.3832, device='cuda:0'),\n",
              " tensor(2.4132, device='cuda:0'),\n",
              " tensor(2.4171, device='cuda:0'),\n",
              " tensor(2.4139, device='cuda:0')]"
            ]
          },
          "metadata": {},
          "execution_count": 389
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy obtained: {:.3f}%\".format(accuracy/len(student_testloader)*100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "2RzU5Iuxhad3",
        "outputId": "9fd00b21-b9f4-485a-c94f-79d4451c3732"
      },
      "execution_count": 380,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy obtained: 23.230%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\n",
        "# ==============================================================================\n",
        "# Modifications copyright (C) 2020 OpenMined\n",
        "#\n",
        "# Added type hints to functions\n",
        "# Added moment values to print statements when calculating sensitivity\n",
        "# ==============================================================================\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "This script computes bounds on the privacy cost of training the\n",
        "student model from noisy aggregation of labels predicted by teachers.\n",
        "It should be used only after training the student (and therefore the\n",
        "teachers as well). We however include the label files required to\n",
        "reproduce key results from our paper (https://arxiv.org/abs/1610.05755):\n",
        "the epsilon bounds for MNIST and SVHN students.\n",
        "\"\"\"\n",
        "import math\n",
        "from typing import List, Tuple, Union\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "\n",
        "def compute_q_noisy_max(counts: Union[np.ndarray, List[float]], noise_eps: float) -> float:\n",
        "    \"\"\"\n",
        "    Returns ~ Pr[outcome != winner].\n",
        "    Args:\n",
        "        counts: a list of scores\n",
        "        noise_eps: privacy parameter for noisy_max\n",
        "    Returns:\n",
        "        q: the probability that outcome is different from true winner.\n",
        "    \"\"\"\n",
        "    # For noisy max, we only get an upper bound.\n",
        "    # Pr[ j beats i*] \\leq (2+gap(j,i*))/ 4 exp(gap(j,i*)\n",
        "    # proof at http://mathoverflow.net/questions/66763/\n",
        "    # tight-bounds-on-probability-of-sum-of-laplace-random-variables\n",
        "\n",
        "    winner = np.argmax(counts)\n",
        "    counts_normalized = noise_eps * (counts - counts[winner])\n",
        "\n",
        "    counts_rest = np.array([counts_normalized[i] for i in range(len(counts)) if i != winner])\n",
        "    q = 0.0\n",
        "\n",
        "    for c in counts_rest:\n",
        "        gap = -c\n",
        "        q += (gap + 2.0) / (4.0 * math.exp(gap))\n",
        "\n",
        "    return min(q, 1.0 - (1.0 / len(counts)))\n",
        "\n",
        "\n",
        "def compute_q_noisy_max_approx(counts: List[float], noise_eps: float) -> float:\n",
        "    \"\"\"\n",
        "    Returns ~ Pr[outcome != winner].\n",
        "    Args:\n",
        "        counts: a list of scores\n",
        "        noise_eps: privacy parameter for noisy_max\n",
        "    Returns:\n",
        "        q: the probability that outcome is different from true winner.\n",
        "    \"\"\"\n",
        "    # For noisy max, we only get an upper bound.\n",
        "    # Pr[ j beats i*] \\leq (2+gap(j,i*))/ 4 exp(gap(j,i*)\n",
        "    # proof at http://mathoverflow.net/questions/66763/\n",
        "    # tight-bounds-on-probability-of-sum-of-laplace-random-variables\n",
        "    # This code uses an approximation that is faster and easier\n",
        "    # to get local sensitivity bound on.\n",
        "\n",
        "    winner = np.argmax(counts)\n",
        "    counts_normalized = noise_eps * (counts - counts[winner])\n",
        "    counts_rest = np.array([counts_normalized[i] for i in range(len(counts)) if i != winner])\n",
        "    gap = -max(counts_rest)\n",
        "    q = (len(counts) - 1) * (gap + 2.0) / (4.0 * math.exp(gap))\n",
        "    return min(q, 1.0 - (1.0 / len(counts)))\n",
        "\n",
        "\n",
        "def logmgf_exact(q: float, priv_eps: float, l: int) -> float:\n",
        "    \"\"\"\n",
        "    Computes the logmgf value given q and privacy eps.\n",
        "    The bound used is the min of three terms. The first term is from\n",
        "    https://arxiv.org/pdf/1605.02065.pdf.\n",
        "    The second term is based on the fact that when event has probability (1-q) for\n",
        "    q close to zero, q can only change by exp(eps), which corresponds to a\n",
        "    much smaller multiplicative change in (1-q)\n",
        "    The third term comes directly from the privacy guarantee.\n",
        "    Args:\n",
        "        q: pr of non-optimal outcome\n",
        "        priv_eps: eps parameter for DP\n",
        "        l: moment to compute.\n",
        "    Returns:\n",
        "        Upper bound on logmgf\n",
        "    \"\"\"\n",
        "    if q < 0.5:\n",
        "        t_one = (1 - q) * math.pow((1 - q) / (1 - math.exp(priv_eps) * q), l)\n",
        "        t_two = q * math.exp(priv_eps * l)\n",
        "        t = t_one + t_two\n",
        "        try:\n",
        "            log_t = math.log(t)\n",
        "        except ValueError:\n",
        "            print(\"Got ValueError in math.log for values :\" + str((q, priv_eps, l, t)))\n",
        "            log_t = priv_eps * l\n",
        "    else:\n",
        "        log_t = priv_eps * l\n",
        "\n",
        "    return min(0.5 * priv_eps * priv_eps * l * (l + 1), log_t, priv_eps * l)\n",
        "\n",
        "\n",
        "def logmgf_from_counts(counts: Union[np.ndarray, List[float]], noise_eps: float, l: int) -> float:\n",
        "    \"\"\"\n",
        "    ReportNoisyMax mechanism with noise_eps with 2*noise_eps-DP\n",
        "    in our setting where one count can go up by one and another\n",
        "    can go down by 1.\n",
        "    Args:\n",
        "        counts: an array of scores\n",
        "        noise_eps: noise epsilon used\n",
        "        l: moment to compute\n",
        "    Returns:\n",
        "        q: Upper bound on logmgf\n",
        "    \"\"\"\n",
        "    q = compute_q_noisy_max(counts, noise_eps)\n",
        "    return logmgf_exact(q, 2.0 * noise_eps, l)\n",
        "\n",
        "\n",
        "def sens_at_k(counts: np.ndarray, noise_eps: float, l: int, k: float) -> float:\n",
        "    \"\"\"\n",
        "    Return sensitivity at distance k.\n",
        "    Args:\n",
        "        counts: an array of scores\n",
        "        noise_eps: noise parameter used\n",
        "        l: moment whose sensitivity is being computed\n",
        "        k: distance\n",
        "    Returns:\n",
        "        sensitivity: at distance k\n",
        "    \"\"\"\n",
        "    counts_sorted = sorted(counts, reverse=True)\n",
        "\n",
        "    if 0.5 * noise_eps * l > 1:\n",
        "        print(f\"l of {l} too large to compute sensitivity with noise epsilon {noise_eps}\")\n",
        "        return 0\n",
        "\n",
        "    # Now we can assume that at k, gap remains positive\n",
        "    # or we have reached the point where logmgf_exact is\n",
        "    # determined by the first term and ind of q.\n",
        "    if counts[0] < counts[1] + k:\n",
        "        return 0\n",
        "\n",
        "    counts_sorted[0] -= k\n",
        "    counts_sorted[1] += k\n",
        "    val = logmgf_from_counts(counts_sorted, noise_eps, l)\n",
        "\n",
        "    counts_sorted[0] -= 1\n",
        "    counts_sorted[1] += 1\n",
        "    val_changed = logmgf_from_counts(counts_sorted, noise_eps, l)\n",
        "\n",
        "    return val_changed - val\n",
        "\n",
        "\n",
        "def smoothed_sens(counts: np.ndarray, noise_eps: float, l: int, beta: float) -> float:\n",
        "    \"\"\"\n",
        "    Compute beta-smooth sensitivity.\n",
        "    Args:\n",
        "        counts: array of scores\n",
        "        noise_eps: noise parameter\n",
        "        l: moment of interest\n",
        "        beta: smoothness parameter\n",
        "    Returns:\n",
        "        smooth_sensitivity: a beta smooth upper bound\n",
        "    \"\"\"\n",
        "    k = 0\n",
        "    smoothed_sensitivity = sens_at_k(counts, noise_eps, l, k)\n",
        "\n",
        "    while k < max(counts):\n",
        "        k += 1\n",
        "        sensitivity_at_k = sens_at_k(counts, noise_eps, l, k)\n",
        "        smoothed_sensitivity = max(smoothed_sensitivity, math.exp(-beta * k) * sensitivity_at_k)\n",
        "\n",
        "        if sensitivity_at_k == 0.0:\n",
        "            break\n",
        "\n",
        "    return smoothed_sensitivity\n",
        "\n",
        "\n",
        "def perform_analysis(\n",
        "    teacher_preds: np.ndarray,\n",
        "    indices: np.ndarray,\n",
        "    noise_eps: float,\n",
        "    delta: float = 1e-5,\n",
        "    moments: int = 8,\n",
        "    beta: float = 0.09,\n",
        ") -> Tuple[float, float]:\n",
        "    \"\"\"\n",
        "    Performs PATE analysis on predictions from teachers and combined predictions for student.\n",
        "    Args:\n",
        "        teacher_preds: a numpy array of dim (num_teachers x num_examples). Each value corresponds\n",
        "            to the index of the label which a teacher gave for a specific example\n",
        "        indices: a numpy array of dim (num_examples) of aggregated examples which were aggregated\n",
        "            using the noisy max mechanism.\n",
        "        noise_eps: the epsilon level used to create the indices\n",
        "        delta: the desired level of delta\n",
        "        moments: the number of moments to track (see the paper)\n",
        "        beta: a smoothing parameter (see the paper)\n",
        "    Returns:\n",
        "        tuple: first value is the data dependent epsilon, then the data independent epsilon\n",
        "    \"\"\"\n",
        "    num_teachers, num_examples = teacher_preds.shape\n",
        "    _num_examples = indices.shape[0]\n",
        "    labels = set(teacher_preds.flatten())\n",
        "    num_labels = len(labels)\n",
        "\n",
        "    if num_examples != _num_examples:\n",
        "        raise ValueError(\"Check the shape of teacher_preds & indices.\")\n",
        "\n",
        "    counts_mat = np.zeros((num_examples, num_labels))\n",
        "\n",
        "    for i in range(num_examples):\n",
        "        for j in range(num_teachers):\n",
        "            counts_mat[i, int(teacher_preds[j, i])] += 1\n",
        "\n",
        "    l_list = 1.0 + np.array(range(moments))\n",
        "\n",
        "    total_log_mgf_nm = np.array([0.0 for _ in l_list])\n",
        "    total_ss_nm = np.array([0.0 for _ in l_list])\n",
        "\n",
        "    for i in indices:\n",
        "        total_log_mgf_nm += np.array(\n",
        "            [logmgf_from_counts(counts_mat[i], noise_eps, l) for l in l_list]\n",
        "        )\n",
        "\n",
        "        total_ss_nm += np.array([smoothed_sens(counts_mat[i], noise_eps, l, beta) for l in l_list])\n",
        "\n",
        "    # We want delta = exp(alpha - eps l).\n",
        "    # Solving gives eps = (alpha - ln (delta))/l\n",
        "\n",
        "    eps_list_nm = (total_log_mgf_nm - math.log(delta)) / l_list\n",
        "\n",
        "    # If beta < eps / 2 ln (1/delta), then adding noise Lap(1) * 2 SS/eps\n",
        "    # is eps,delta DP\n",
        "    # Also if beta < eps / 2(gamma +1), then adding noise 2(gamma+1) SS eta / eps\n",
        "    # where eta has density proportional to 1 / (1+|z|^gamma) is eps-DP\n",
        "    # Both from Corolloary 2.4 in\n",
        "    # http://www.cse.psu.edu/~ads22/pubs/NRS07/NRS07-full-draft-v1.pdf\n",
        "    # Print the first one's scale\n",
        "\n",
        "    ss_eps = 2.0 * beta * math.log(1 / delta)\n",
        "\n",
        "    if min(eps_list_nm) == eps_list_nm[-1]:\n",
        "        print(\n",
        "            \"Warning: May not have used enough values of l. Increase 'moments' variable and \"\n",
        "            \"run again.\"\n",
        "        )\n",
        "\n",
        "    # Data independent bound, as mechanism is\n",
        "    # 2*noise_eps DP.\n",
        "    data_ind_log_mgf = np.array([0.0 for _ in l_list])\n",
        "    data_ind_log_mgf += num_examples * np.array(\n",
        "        [logmgf_exact(1.0, 2.0 * noise_eps, l) for l in l_list]\n",
        "    )\n",
        "\n",
        "    data_ind_eps_list = (data_ind_log_mgf - math.log(delta)) / l_list\n",
        "\n",
        "    return min(eps_list_nm), min(data_ind_eps_list)\n",
        "\n",
        "\n",
        "def tensors_to_literals(tensor_list: List[torch.Tensor]) -> List[Union[float, int]]:\n",
        "    \"\"\"\n",
        "    Converts list of torch tensors to list of integers/floats. Fix for not having the functionality\n",
        "    which converts list of tensors to tensors\n",
        "    Args:\n",
        "        tensor_list: List of torch tensors\n",
        "    Returns:\n",
        "        literal_list: List of floats/integers\n",
        "    \"\"\"\n",
        "    literal_list = []\n",
        "\n",
        "    for tensor in tensor_list:\n",
        "        literal_list.append(tensor.item())\n",
        "\n",
        "    return literal_list\n",
        "\n",
        "\n",
        "def logmgf_exact_torch(q: float, priv_eps: float, l: int) -> float:\n",
        "    \"\"\"\n",
        "    Computes the logmgf value given q and privacy eps.\n",
        "    The bound used is the min of three terms. The first term is from\n",
        "    https://arxiv.org/pdf/1605.02065.pdf.\n",
        "    The second term is based on the fact that when event has probability (1-q) for\n",
        "    q close to zero, q can only change by exp(eps), which corresponds to a\n",
        "    much smaller multiplicative change in (1-q)\n",
        "    The third term comes directly from the privacy guarantee.\n",
        "    Args:\n",
        "        q: pr of non-optimal outcome\n",
        "        priv_eps: eps parameter for DP\n",
        "        l: moment to compute.\n",
        "    Returns:\n",
        "        Upper bound on logmgf\n",
        "    \"\"\"\n",
        "    if q < 0.5:\n",
        "        t_one = (1 - q) * math.pow((1 - q) / (1 - math.exp(priv_eps) * q), l)\n",
        "        t_two = q * math.exp(priv_eps * l)\n",
        "        t = t_one + t_two\n",
        "\n",
        "        try:\n",
        "            log_t = math.log(t)\n",
        "        except ValueError:\n",
        "            print(\"Got ValueError in math.log for values :\" + str((q, priv_eps, l, t)))\n",
        "            log_t = priv_eps * l\n",
        "    else:\n",
        "        log_t = priv_eps * l\n",
        "\n",
        "    return min(0.5 * priv_eps * priv_eps * l * (l + 1), log_t, priv_eps * l)\n",
        "\n",
        "\n",
        "def compute_q_noisy_max_torch(\n",
        "    counts: Union[List[torch.Tensor], torch.Tensor], noise_eps: float\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Returns ~ Pr[outcome != winner].\n",
        "    Args:\n",
        "        counts: a list of scores\n",
        "        noise_eps: privacy parameter for noisy_max\n",
        "    Returns:\n",
        "        q: the probability that outcome is different from true winner.\n",
        "    \"\"\"\n",
        "    if type(counts) != torch.tensor:\n",
        "        counts = torch.tensor(tensors_to_literals(counts), dtype=torch.float)\n",
        "\n",
        "    _, winner = counts.max(0)\n",
        "    counts_normalized = noise_eps * (counts.clone().detach().type(torch.float) - counts[winner])\n",
        "\n",
        "    counts_normalized = tensors_to_literals(counts_normalized)\n",
        "    counts_rest = torch.tensor(\n",
        "        [counts_normalized[i] for i in range(len(counts)) if i != winner], dtype=torch.float\n",
        "    )\n",
        "    q = 0.0\n",
        "\n",
        "    index = 0\n",
        "    for c in counts_rest:\n",
        "        gap = -c\n",
        "        q += (gap + 2.0) / (4.0 * math.exp(gap))\n",
        "\n",
        "        index += 1\n",
        "\n",
        "    return min(q, 1.0 - (1.0 / len(counts)))\n",
        "\n",
        "\n",
        "def logmgf_from_counts_torch(\n",
        "    counts: Union[List[torch.Tensor], torch.Tensor], noise_eps: float, l: int\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    ReportNoisyMax mechanism with noise_eps with 2*noise_eps-DP\n",
        "    in our setting where one count can go up by one and another\n",
        "    can go down by 1.\n",
        "    Args:\n",
        "        counts: a list of scores\n",
        "        noise_eps: noise parameter used\n",
        "        l: moment whose sensitivity is being computed\n",
        "    Returns:\n",
        "        q: the probability that outcome is different from true winner\n",
        "    \"\"\"\n",
        "    q = compute_q_noisy_max_torch(counts, noise_eps)\n",
        "\n",
        "    return logmgf_exact_torch(q, 2.0 * noise_eps, l)\n",
        "\n",
        "\n",
        "def sens_at_k_torch(counts: torch.Tensor, noise_eps: float, l: int, k: int) -> float:\n",
        "    \"\"\"\n",
        "    Return sensitivity at distane k.\n",
        "    Args:\n",
        "        counts: tensor of scores\n",
        "        noise_eps: noise parameter used\n",
        "        l: moment whose sensitivity is being computed\n",
        "        k: distance\n",
        "    Returns:\n",
        "        sensitivity: at distance k\n",
        "    \"\"\"\n",
        "\n",
        "    counts_sorted = sorted(counts, reverse=True)\n",
        "\n",
        "    if 0.5 * noise_eps * l > 1:\n",
        "        print(f\"l of {l} is too large to compute sensitivity with noise epsilon {noise_eps}\")\n",
        "        return 0\n",
        "\n",
        "    if counts[0] < counts[1] + k:\n",
        "        return 0\n",
        "\n",
        "    counts_sorted[0] -= k\n",
        "    counts_sorted[1] += k\n",
        "    val = logmgf_from_counts_torch(counts_sorted, noise_eps, l)\n",
        "\n",
        "    counts_sorted[0] -= 1\n",
        "    counts_sorted[1] += 1\n",
        "    val_changed = logmgf_from_counts_torch(counts_sorted, noise_eps, l)\n",
        "\n",
        "    return val_changed - val\n",
        "\n",
        "\n",
        "def smooth_sens_torch(counts: torch.Tensor, noise_eps: float, l: int, beta: float) -> float:\n",
        "    \"\"\"Compute beta-smooth sensitivity.\n",
        "    Args:\n",
        "        counts: tensor of scores\n",
        "        noise_eps: noise parameter\n",
        "        l: moment of interest\n",
        "        beta: smoothness parameter\n",
        "    Returns:\n",
        "        smooth_sensitivity: a beta smooth upper bound\n",
        "    \"\"\"\n",
        "    k = 0\n",
        "    smoothed_sensitivity = sens_at_k_torch(counts, noise_eps, l, k)\n",
        "\n",
        "    while k < max(counts):\n",
        "        k += 1\n",
        "        sensitivity_at_k = sens_at_k_torch(counts, noise_eps, l, k)\n",
        "        smoothed_sensitivity = max(smoothed_sensitivity, math.exp(-beta * k) * sensitivity_at_k)\n",
        "\n",
        "        if sensitivity_at_k == 0.0:\n",
        "            break\n",
        "\n",
        "    return smoothed_sensitivity\n",
        "\n",
        "\n",
        "def perform_analysis_torch(\n",
        "    preds: torch.Tensor,\n",
        "    indices: torch.Tensor,\n",
        "    noise_eps: float = 0.1,\n",
        "    delta: float = 1e-5,\n",
        "    moments: int = 8,\n",
        "    beta: float = 0.09,\n",
        ") -> Tuple[float, float]:\n",
        "    \"\"\"\n",
        "    Performs PATE analysis on predictions from teachers and combined predictions for student.\n",
        "    Args:\n",
        "        preds: a torch tensor of dim (num_teachers x num_examples). Each value corresponds to the\n",
        "            index of the label which a teacher gave for a specific example\n",
        "        indices: a torch tensor of dim (num_examples) of aggregated examples which were aggregated\n",
        "            using the noisy max mechanism.\n",
        "        noise_eps: the epsilon level used to create the indices\n",
        "        delta: the desired level of delta\n",
        "        moments: the number of moments to track (see the paper)\n",
        "        beta: a smoothing parameter (see the paper)\n",
        "    Returns:\n",
        "        tuple: first value is the data dependent epsilon, then the data independent epsilon\n",
        "    \"\"\"\n",
        "    num_teachers, num_examples = preds.shape\n",
        "    _num_examples = indices.shape[0]\n",
        "\n",
        "    # Check that preds is shape (teachers x examples)\n",
        "    if num_examples != _num_examples:\n",
        "        raise ValueError(\"Check the shape of preds & indices.\")\n",
        "\n",
        "    labels = list(preds.flatten())\n",
        "    labels = {tensor.item() for tensor in labels}\n",
        "    num_labels = len(labels)\n",
        "\n",
        "    counts_mat = torch.zeros(num_examples, num_labels, dtype=torch.float32)\n",
        "\n",
        "    # Count number of teacher predictions of each label for each example\n",
        "    for i in range(num_examples):\n",
        "        for j in range(num_teachers):\n",
        "            counts_mat[i, int(preds[j, i])] += 1\n",
        "\n",
        "    l_list = 1 + torch.tensor(range(moments), dtype=torch.float)\n",
        "\n",
        "    total_log_mgf_nm = torch.tensor([0.0 for _ in l_list], dtype=torch.float)\n",
        "    total_ss_nm = torch.tensor([0.0 for _ in l_list], dtype=torch.float)\n",
        "\n",
        "    for i in indices:\n",
        "        total_log_mgf_nm += torch.tensor(\n",
        "            [logmgf_from_counts_torch(counts_mat[i].clone(), noise_eps, l) for l in l_list]\n",
        "        )\n",
        "\n",
        "        total_ss_nm += torch.tensor(\n",
        "            [smooth_sens_torch(counts_mat[i].clone(), noise_eps, l, beta) for l in l_list],\n",
        "            dtype=torch.float,\n",
        "        )\n",
        "\n",
        "    eps_list_nm = (total_log_mgf_nm - math.log(delta)) / l_list\n",
        "    ss_eps = 2.0 * beta * math.log(1 / delta)\n",
        "\n",
        "    if min(eps_list_nm) == eps_list_nm[-1]:\n",
        "        print(\n",
        "            \"Warning: May not have used enough values of l. Increase 'moments' variable \"\n",
        "            \"and run again.\"\n",
        "        )\n",
        "\n",
        "    # Computer epsilon when not taking teacher quorum into account\n",
        "    data_ind_log_mgf = torch.tensor([0.0 for _ in l_list])\n",
        "    data_ind_log_mgf += num_examples * torch.tensor(\n",
        "        tensors_to_literals([logmgf_exact_torch(1.0, 2.0 * noise_eps, l) for l in l_list])\n",
        "    )\n",
        "\n",
        "    data_ind_eps_list = (data_ind_log_mgf - math.log(delta)) / l_list\n",
        "\n",
        "    return min(eps_list_nm), min(data_ind_eps_list)"
      ],
      "metadata": {
        "id": "ylnkOcyAVeH7"
      },
      "execution_count": 381,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dep_eps, data_ind_eps = perform_analysis(teacher_preds=preds, indices=student_labels, noise_eps=epsilon, delta=1e-5)\n",
        "print(\"Data Independent Epsilon:\", data_ind_eps) \n",
        "print(\"Data Dependent Epsilon:\", data_dep_eps) #Is the Epsilon value obtained by looking at how much teacher agree with each other"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "TPh8fwKqhX9_",
        "outputId": "2043bf64-7ca4-42f4-cc19-b28d5a93be68"
      },
      "execution_count": 382,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Independent Epsilon: 161.51292546497024\n",
            "Data Dependent Epsilon: 161.51292546497024\n"
          ]
        }
      ]
    }
  ]
}